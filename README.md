<p align="center">
  <img src="https://img.shields.io/badge/âš–ï¸-JudgeMate--AI-7c3aed?style=for-the-badge&labelColor=1e1b4b" alt="JudgeMate-AI" />
</p>
 Link : https://judge-mate.vercel.app/
<h1 align="center">JudgeMate-AI</h1>

<p align="center">
  <b>AI-Powered Hackathon Judging Platform</b><br/>
  Built for <em>Hack With Mumbai 2.0</em>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/React-18.3-61DAFB?logo=react&logoColor=white" alt="React" />
  <img src="https://img.shields.io/badge/TypeScript-5.8-3178C6?logo=typescript&logoColor=white" alt="TypeScript" />
  <img src="https://img.shields.io/badge/Vite-5.4-646CFF?logo=vite&logoColor=white" alt="Vite" />
  <img src="https://img.shields.io/badge/Tailwind_CSS-3.4-06B6D4?logo=tailwindcss&logoColor=white" alt="Tailwind" />
  <img src="https://img.shields.io/badge/Supabase-Hosted-3FCF8E?logo=supabase&logoColor=white" alt="Supabase" />
  <img src="https://img.shields.io/badge/xAI_Grok-AI_Scoring-000000?logo=x&logoColor=white" alt="xAI" />
</p>

---

## ðŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Tech Stack](#tech-stack)
- [Architecture](#architecture)
- [Project Structure](#project-structure)
- [Getting Started](#getting-started)
- [Environment Variables](#environment-variables)
- [Deployment](#deployment)
- [API Endpoints](#api-endpoints)
- [Scoring Criteria](#scoring-criteria)
- [Screenshots](#screenshots)
- [Contributing](#contributing)
- [License](#license)

---

## Overview

**JudgeMate-AI** is a full-stack, AI-powered hackathon judging platform that automates project evaluation across 8 weighted criteria. Judges can review submissions, trigger AI scoring, analyze GitHub repositories, detect plagiarism, and export rankings â€” all from a single dashboard.

Students submit their projects (with GitHub links, descriptions, and PPT files), and the platform automatically analyzes code quality, commit history, and originality using real GitHub API data and large language models.

---

## Features

### ðŸŽ“ Student Portal
- **Project Submission** â€” Team name, project name, description, domain selection, GitHub URL, and PPT upload
- **GitHub Integration** â€” Automatic repository analysis (commits, languages, structure, contributors)
- **Real-time Validation** â€” Form validation, GitHub URL format checking, and duplicate submission prevention
- **Plagiarism Detection** â€” Instant plagiarism risk scoring with detailed breakdown

### ðŸ§‘â€âš–ï¸ Judge Dashboard
- **AI Scoring** â€” One-click AI evaluation powered by xAI (Grok) with detailed explanations per criterion
- **Manual Scoring** â€” Judges can also score projects manually with custom questions
- **Plagiarism Analysis** â€” AI pattern detection, boilerplate matching, commit history analysis, and code modularity scoring
- **Re-scoring** â€” Full re-analysis capability (re-fetches GitHub data, re-runs plagiarism, re-scores with AI)
- **Rankings** â€” Real-time leaderboard sorted by weighted AI scores
- **CSV Export** â€” Export all rankings with per-criterion scores to CSV
- **Notifications** â€” Real-time notification system for new submissions and score updates
- **Filters & Search** â€” Filter projects by domain, search by team/project name

### ðŸ¤– AI & Analysis
- **8-Criterion Scoring** â€” Innovation, Technical Feasibility, Impact, MVP Completeness, Presentation, Code Quality, Team Collaboration, Originality
- **GitHub Repository Analysis** â€” Commits, contributors, languages, stars, forks, file structure, modularity
- **Plagiarism Detection** â€” Multi-signal detection (AI patterns, boilerplate, commit history, code modularity)
- **AI Mentorship** â€” Improvement suggestions, action plans, and tech recommendations
- **Recommendation Engine** â€” Smart question generation for judges based on project data

### ðŸŽ¨ UI/UX
- **Dark/Light Theme** â€” Full theme toggle with persistent preference
- **Responsive Design** â€” Mobile-first, works on all screen sizes
- **Glassmorphism UI** â€” Modern backdrop-blur cards with gradient accents
- **PPT Viewer** â€” In-browser PowerPoint file preview

---

## Tech Stack

| Layer | Technology |
|-------|-----------|
| **Frontend** | React 18, TypeScript 5.8, Vite 5.4 |
| **Styling** | Tailwind CSS 3.4, Shadcn/UI (Radix Primitives) |
| **State** | TanStack React Query, localStorage |
| **Routing** | React Router 6 |
| **Charts** | Recharts |
| **Backend API** | Express.js, TypeScript, Helmet, CORS, Rate Limiting |
| **AI** | xAI (Grok) API via backend proxy |
| **Database** | Supabase (PostgreSQL) |
| **Edge Functions** | Supabase Edge Functions (Deno) + Groq API |
| **Auth** | Local auth (localStorage-based) |
| **Deployment** | Frontend â†’ Vercel, Backend â†’ Render, DB â†’ Supabase |

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend   â”‚â”€â”€â”€â”€â–¶â”‚   Backend API    â”‚â”€â”€â”€â”€â–¶â”‚   xAI/Grok  â”‚
â”‚   (Vercel)   â”‚     â”‚   (Render)       â”‚     â”‚   API       â”‚
â”‚              â”‚     â”‚                  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  React+Vite  â”‚     â”‚  Express+TS      â”‚
â”‚  Shadcn UI   â”‚     â”‚  Helmet+CORS     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ (Supabase JS Client)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Supabase      â”‚
â”‚  (PostgreSQL +   â”‚
â”‚  Edge Functions) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Frontend** sends scoring/mentorship requests to the **Backend API**
- **Backend** securely calls xAI (Grok) with the API key â€” never exposed to the client
- **Supabase** handles data storage (teams, scores, user roles) and has its own edge function for Groq-based scoring
- If the backend is unavailable, the frontend gracefully falls back to client-side rule-based scoring

---

## Project Structure

```
â”œâ”€â”€ public/                     # Static assets
â”œâ”€â”€ server/                     # Backend API (Express.js)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ index.ts            # Entry point â€” CORS, rate limiting, routes
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ health.ts       # GET  /api/health
â”‚   â”‚   â”‚   â”œâ”€â”€ scoring.ts      # POST /api/score
â”‚   â”‚   â”‚   â””â”€â”€ mentorship.ts   # POST /api/mentorship
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â””â”€â”€ xai.ts          # xAI (Grok) API client
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â””â”€â”€ .env.example
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ErrorBoundary.tsx    # Global error boundary
â”‚   â”‚   â”œâ”€â”€ StudentLogin.tsx     # Auth page (student/judge)
â”‚   â”‚   â”œâ”€â”€ ProjectSubmission.tsx# Student submission form
â”‚   â”‚   â”œâ”€â”€ JudgeDashboard.tsx   # Judge dashboard with stats & filters
â”‚   â”‚   â”œâ”€â”€ JudgeTeamCard.tsx    # Individual project card (scoring, plagiarism)
â”‚   â”‚   â”œâ”€â”€ JudgeRankingsTable.tsx# Rankings leaderboard
â”‚   â”‚   â”œâ”€â”€ AIMentorshipPanel.tsx# AI mentorship panel
â”‚   â”‚   â”œâ”€â”€ PlagiarismDetector.tsx# Plagiarism details display
â”‚   â”‚   â”œâ”€â”€ RecommendationEngine.tsx# Smart question generator
â”‚   â”‚   â”œâ”€â”€ PPTViewer.tsx        # PowerPoint viewer
â”‚   â”‚   â”œâ”€â”€ ThemeToggle.tsx      # Dark/light mode toggle
â”‚   â”‚   â””â”€â”€ ui/                  # Shadcn/UI components (40+ components)
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ useLocalAuth.tsx     # Authentication hook (localStorage)
â”‚   â”‚   â”œâ”€â”€ useProjects.ts       # Project CRUD hook
â”‚   â”‚   â”œâ”€â”€ useNotifications.ts  # Notification system hook
â”‚   â”‚   â””â”€â”€ useLocalStorage.ts   # Generic localStorage hook
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ apiClient.ts         # Backend API client (proxy)
â”‚   â”‚   â”œâ”€â”€ aiScoring.ts         # Client-side rule-based AI scoring
â”‚   â”‚   â”œâ”€â”€ groqScoring.ts       # xAI scoring (backend proxy + fallback)
â”‚   â”‚   â”œâ”€â”€ aiMentorship.ts      # AI mentorship (backend proxy + fallback)
â”‚   â”‚   â”œâ”€â”€ githubAnalyzer.ts    # GitHub repository analyzer
â”‚   â”‚   â”œâ”€â”€ plagiarism.ts        # Plagiarism detection engine
â”‚   â”‚   â”œâ”€â”€ recommendations.ts   # Question recommendation engine
â”‚   â”‚   â””â”€â”€ scoring.ts           # Scoring utilities & criteria
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ Landing.tsx          # Landing page
â”‚   â”‚   â”œâ”€â”€ Dashboard.tsx        # Legacy dashboard
â”‚   â”‚   â””â”€â”€ NotFound.tsx         # 404 page
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â””â”€â”€ index.ts             # All TypeScript types & constants
â”‚   â”œâ”€â”€ App.tsx                  # Routes & providers
â”‚   â””â”€â”€ main.tsx                 # Entry point
â”œâ”€â”€ supabase/
â”‚   â”œâ”€â”€ functions/
â”‚   â”‚   â””â”€â”€ score-team/
â”‚   â”‚       â””â”€â”€ index.ts         # Deno edge function (Groq scoring)
â”‚   â”œâ”€â”€ migrations/              # Database migrations
â”‚   â””â”€â”€ config.toml              # Supabase config
â”œâ”€â”€ vercel.json                  # Vercel deployment config
â”œâ”€â”€ render.yaml                  # Render deployment config (Blueprint)
â”œâ”€â”€ DEPLOYMENT.md                # Detailed deployment guide
â”œâ”€â”€ .env.example                 # Frontend env template
â”œâ”€â”€ tailwind.config.ts
â”œâ”€â”€ vite.config.ts
â””â”€â”€ tsconfig.json
```

---

## Getting Started

### Prerequisites

- **Node.js** â‰¥ 18 â€” [Install with nvm](https://github.com/nvm-sh/nvm#installing-and-updating)
- **npm** â‰¥ 9
- **Git**

### 1. Clone the repository

```bash
git clone https://github.com/your-username/judgemate-ai.git
cd judgemate-ai
```

### 2. Install frontend dependencies

```bash
npm install
```

### 3. Set up environment variables

```bash
cp .env.example .env
```

Edit `.env` with your keys:

```env
VITE_SUPABASE_URL=https://your-project.supabase.co
VITE_SUPABASE_PUBLISHABLE_KEY=your_anon_key
VITE_API_URL=http://localhost:3001
```

### 4. Start the frontend

```bash
npm run dev
# â†’ http://localhost:8080
```

### 5. Set up the backend (optional â€” enables AI scoring)

```bash
cd server
npm install
cp .env.example .env
# Edit server/.env with your XAI_API_KEY, SUPABASE_URL, SUPABASE_SERVICE_KEY
npm run dev
# â†’ http://localhost:3001
```

### 6. Verify

- Frontend: `http://localhost:8080`
- Backend health: `http://localhost:3001/api/health`

---

## Environment Variables

### Frontend (Vercel)

| Variable | Description | Required |
|----------|-------------|----------|
| `VITE_SUPABASE_URL` | Supabase project URL | Yes |
| `VITE_SUPABASE_PUBLISHABLE_KEY` | Supabase anon/public key | Yes |
| `VITE_API_URL` | Backend API URL (Render) | Yes |

> âš ï¸ **Do NOT set `VITE_XAI_API_KEY` in production** â€” AI calls are routed through the backend proxy.

### Backend (Render)

| Variable | Description | Required |
|----------|-------------|----------|
| `XAI_API_KEY` | xAI (Grok) API key | Yes |
| `SUPABASE_URL` | Supabase project URL | Yes |
| `SUPABASE_SERVICE_KEY` | Supabase service role key | Yes |
| `ALLOWED_ORIGINS` | Frontend URL(s) for CORS | Yes |
| `PORT` | Server port (default: 3001) | No |

### Supabase Edge Functions

| Variable | Description |
|----------|-------------|
| `GROQ_API_KEY` | Groq API key (set via `supabase secrets set`) |

---

## Deployment

See [DEPLOYMENT.md](DEPLOYMENT.md) for full step-by-step deployment instructions.

**Quick summary:**

| Service | Platform | Config File |
|---------|----------|-------------|
| Frontend | Vercel | `vercel.json` |
| Backend | Render | `render.yaml` |
| Database | Supabase | Already hosted |

---

## API Endpoints

### Backend API (Render)

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/health` | Health check â€” returns configured service status |
| `POST` | `/api/score` | AI-score a project (GitHub URL, description, domain) |
| `POST` | `/api/mentorship` | Get AI mentorship (improvements, action plan, tech suggestions) |

### Supabase Edge Function

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/functions/v1/score-team` | Score a project via Groq (Llama 3.3 70B) |

---

## Scoring Criteria

| Criterion | Weight | Description |
|-----------|--------|-------------|
| ðŸ’¡ Innovation | 25% | Novelty and creativity of the idea |
| âš™ï¸ Technical Feasibility | 20% | Technical implementation quality |
| ðŸš€ Impact / Potential | 20% | Real-world impact and scalability |
| âœ… MVP Completeness | 10% | Working prototype completeness |
| ðŸŽ¤ Presentation | 10% | Clarity of description and pitch |
| ðŸ“ Code Quality | 5% | Code structure, modularity, best practices |
| ðŸ¤ Team Collaboration | 5% | Git activity, contributors, commit patterns |
| ðŸŽ¯ Originality | 5% | Uniqueness vs. boilerplate/templates |

**Total weighted score: 1â€“10 scale**

---

## Screenshots

> _Add screenshots of the landing page, student submission form, judge dashboard, and AI scoring results here._

---

## Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## License

This project is built for **Hack With Mumbai 2.0**. All rights reserved.
